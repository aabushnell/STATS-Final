---
title: "Tweets"
author: "Aaron Bushnell"
date: "12/2/2018"
output: html_document
---

```{r setup, include=FALSE}
library(readr)
library(mdsr)
library(tidyr)
library(tidyverse)
library(rlang)
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
nouns <- read_csv('most-common-nouns-english.csv')
words_file <- read_csv('words.csv')
words <- words_file$Words


text <- rt %>%
  select(screen_name, text)


match_words <- function(tweet){
  matched_values <- sapply(words, grepl, tweet)
  
  return(matched_values)
}

data.frame(mapply(match_words, text$text))

most_common_words <- function(df){
  text_matches <- data.frame(mapply(match_words, df$text)) 
  
  word_occurences <- text_matches %>%
    cbind(rownames(text_matches)) %>%
    rename(word = 'rownames(text_matches)') %>%
    mutate(occurences = rowSums(. == TRUE)) %>%
    select(word, occurences) %>%
    arrange(desc(occurences))
  
  return(word_occurences)
}

most_common_words(rt)

top_n_words <- function(df, n) {
  words <- most_common_words(df) %>%
    select(word)
  
  top_words <- list()
  for (i in 1:n) {
    top_words[i] <- as.character(words$word)[i]
  }
  return(top_words)
}

top_n_words(rt, 5)

top_n_icons <- function(df, n){
  words <- top_n_words(df, n)
  
  urls <- list()
  for (i in 1:n) {
    endpoint <- paste("icon", words[i], sep = "/")
    res <- get_nouns_api(endpoint = endpoint)
    icon_res <- content(res,"parsed")
    urls[i] <- icon_res$icon$preview_url
  }
  
  return(urls)
}

top_n_icons(rt, 5)


nouns_app <- oauth_app("nouns_api", "", "")

get_nouns_api <- function(endpoint, baseurl = "http://api.thenounproject.com/", app = nouns_app) {
  url <- modify_url(baseurl, path = endpoint)
  info <- oauth_signature(url, app = app)
  header_oauth <- oauth_header(info)
  GET(url, header_oauth)
}

```


```{r}
present_words <- function(df, col_num){
  words_present <- df %>%
  gather(word, present) %>%
  filter(present == TRUE)
  
  return(words_present)
}

present_words(matched)
```

```{r}
state_data <- data.frame(words) %>%
  rename(word = words)
for (name in c("California","Iowa","Nevada")) {
  q = lookup_coords(name, apikey = "AIzaSyBtt_cqXkkEYIewZp5ZYp1fdhUksN92OA8")

  rt <- search_tweets(
  "lang:en", geocode = q, n = 500)
  
  num_rows <- rt %>%
    summarise(n())
  num_rows$`n()`
  
  rt_words <- most_common_words(rt) %>%
    mutate(occurences = occurences / num_rows$`n()`) %>%
    inner_join(state_data, by = 'word') %>%
    rename(!!name := occurences)
  state_data <- rt_words
  
}

states <- map_data("state")

state_data_trans <- state_data %>%
  gather(State, proportion, -word) %>%
  spread(word, proportion) %>%
  mutate(State = tolower(State))

matched_state_data <- states %>%
  rename(map_group = group) %>%
  full_join(state_data_trans, by = c('region' = 'State'))

MapPlot <- function(ds, cfill) {
  ggplot(ds, aes(x = long, y = lat, fill = !! sym(cfill), group = map_group), color = "white") + 
    coord_fixed(1.3) +
    geom_polygon(alpha = 0.7) +
    geom_polygon(color = "black", fill = NA) +
    theme_bw() +
    theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_blank(),
    axis.line = element_blank(),
    axis.ticks = element_blank(),
    panel.border = element_blank(),
    panel.grid = element_blank(),
    axis.title = element_blank()
  )
}

selected_word <- "art"

MapPlot(matched_state_data, selected_word)

```
